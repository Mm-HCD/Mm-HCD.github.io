<!DOCTYPE html>
<html lang='en'>

<head>
    <base href=".">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png">
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css">
    <meta charset="utf-8">
    <meta name="description" content="Multimodal Frameworks in Healthcare Diagnostics 2025">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Workshop, Reasoning, Learning, Spatio-Temporal Information">
    <meta name="google-site-verification" content="PmOT4QwF1x9TSSKYFg6if9CR_TojuEk8pFDffRgdfns">
    <meta name="twitter:card" content="summary_large_image">
    <meta property="og:title" content="Mm-HCD:Multimodal Frameworks in Healthcare Diagnostics ">
    <meta property="og:description" content="In this workshop, we invite the research community in artificial intelligence to submit works related to the integration of spatial and temporal reasoning with machine learning.">
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('consent', 'default', {
        'ad_storage': 'denied',
        'ad_user_data': 'denied',
        'ad_personalization': 'denied',
        'analytics_storage': 'denied'
      });
    </script> 
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-P77LCK8QPT"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-P77LCK8QPT');
    </script>
    <title>Mm-HCD : Multimodal Frameworks in Healthcare Diagnostics</title>
</head>

<body>

    <div class="banner">
        <img src="assets/Main.jpeg" alt="Workshop Banner" style="width: 100%">
        <div class="top-left">
            <span class="title1"> Special Session  </span> <br>
            <span class="title2"> Mm-HCD:</span> <br>
            <span class="title2"> Multimodal Frameworks</span> <br>
            <span class="title2"> in Healthcare Diagnostics</span> <br>
<!--             <span class="year">MIUA 2025</span> <br> -->
        </div>
        <div class="bottom-right">
             <a target="_blank" href="https://conferences.leeds.ac.uk/miua/">MIUA 2025</a>
        </div>
    </div>

    <table class="navigation">
        <tr>
            <!--<td class="navigation">
                <a title="Conference Home Page" href="#top">Home</a>
            </td>-->
            <td class="navigation">
                <a title="Workshop Program" href="#Program">Program</a> 
            </td>
            <td class="navigation">
                <a title="Call For Papers" href="#CFP">CFP</a>
            </td>
            <td class="navigation">
                <a title="Key Dates" href="#Dates">Dates</a>
            </td>
            <td class="navigation">
                <a title="Submission" href="#Submission">Submission</a>
            </td>
            <td class="navigation">
                <a title="Organizers" href="#Organization">Organizers</a>
            </td>
            <td class="navigation">
                <a title="Venue" href="#Venue">Venue</a>
            </td>
        </tr>
    </table>

    <h2>Mm-HCD 2025 @ MIUA 2025, Leeds, United Kingdom</h2>
<!--     <p>You may find details about the third edition of STRL at: <a target="_blank" href="https://www.lirmm.fr/strl2024/">https://www.lirmm.fr/strl2024/</a></p> -->

    <h2>Introduction</h2>
    <p>Multimodal models in machine learning, particularly deep learning, are transforming medical image analysis by incorporating diverse data modalities, such as medical imaging, digital pathology data, lab reports, patient surveys, audio data, health records, and more. By combining data from multiple modalities (e.g., images, texts, and audio), models offer a more holistic understanding of the data. This comprehensive perspective enhances the accuracy and reliability of detection and diagnostic tasks. In addition, these models pave the way for personalised treatment approaches by providing a thorough understanding of patient conditions. In conclusion, multimodal models represent a pivotal step toward achieving a more accurate, robust, and interpreted solution in healthcare and beyond, underscoring their growing importance across research and real-world applications.</p>
    <p><a href="#top">Go back to the top</a></p>
    
    <h2 id="CFP">Call For Papers</h2>
    
    <p>In this special session, we invite submissions that investigate innovative multimodal approaches in healthcare diagnostics. We are looking for original, high-quality papers on the following topics of interest, but not limited to:</p>
    <h3>Topics</h3>
    <ul>
    <li><strong>Integration of Imaging Modalities</strong>: Techniques combining MRI, CT scans, genomic sequencing, etc for enhanced disease detection and diagnosis.</li>
    <li><strong>Clinical Validation</strong>: Studies validating multimodal approaches in real-world clinical settings</li>
    <li><strong>Data Fusion Techniques</strong>:Methods for effective data fusion from heterogeneous sources.</li>
    <li><strong>Machine Learning and AI</strong>: Applications of deep learning and AI in analysing multimodal data.</li>
<li><strong>Wearable Technology</strong>: Patient-Reported Outcomes: Incorporating qualitative data from patients to improve diagnostic processes.</li>
<li><strong>Interdisciplinary Approaches</strong>: Collaborations between fields such as bioinformatics, radiology, and public health.</li>
<li><strong>Case Studies and Applications</strong>: Real-world implementations of multimodal approaches in clinical settings.</li>
    </ul> 

    <h2 id="Dates">Key Dates</h2>
    <ul>
    <li><strong>Paper Submission Deadline: Monday 24 March 2025</li>
    <li><strong>Author Notification : Friday 2 May 2025</li>
    <li><strong>Camera-ready regular papers due: Monday 2 June 2025 </li>
    <li>Early bird and oral presenters registration deadline: Monday 9 June 2025</li>
    <li>Registration close: Friday 20 June 2025</li>
    <li>Conference: Tuesday 15 - Thursday 17 July 2025</li>
    
    </ul> 
<p><em><u>Note</u></em>: The  deadline will be 11:59, Greenwich Mean Time (GMT), on Monday 24 March 2025.</p> 
    
    <h2 id="Submission">Submission</h2>
    <p>Submission is now open via CMT, <a target="_blank" href="https://cmt3.research.microsoft.com/User/Login?ReturnUrl=%2FMIUA2025%2F"> click here to submit</a>.</p>
    <p>For more information on how to create a CMT account, <a target="_blank" href="https://cmt3.research.microsoft.com/docs/help/general/account-creation.html"> click here</a>.</p>
    
    <h4>Guidelines</h4>
    <p>Authors are invited to submit full papers of length between 8 and 15 pages (1 column â€“ the LNCS template, <a target="_blank" href="https://www.ijcai.org/authors_kit">word </a>, <a target="_blank" href=" https://resource-cms.springernature.com/springer-cms/rest/v1/content/19238648/data/v8">latex </a>,<a target="_blank" href=" https://www.overleaf.com/latex/templates/springer-lecture-notes-in-computer-science/kzwwpvhwnvfj#.WuA4JS5uZpi"> overleaf </a>) and following the <a target="_blank" href="https://www.ijcai.org/authors_kit">Springer Author Guidelines </a>, showing original research contributions related to the Special session theme. All submissions will be double-blind peer-reviewed and accepted articles will be published as MIUA Proceedings by the Springer Publishing Group.</p>

<!--     <p>Papers should be formatted according to the <a target="_blank" href="https://www.ijcai.org/authors_kit">IJCAI-ECAI 2022 formatting guidelines</a> and submitted as a single PDF file. We welcome submissions across the full spectrum of theoretical and practical work including research ideas, methods, tools, simulations, applications or demos, practical evaluations, and surveys. Submissions that are <em>2 pages long</em> (excluding references and appendices) will be considered for a <em>poster</em>, and submissions that are <em>at least 4 pages and up to 6 pages long</em> (excluding references and appendices) will be considered for an <em>oral presentation</em>. All papers will be peer-reviewed in a <em>single-blind</em> process and assessed based on their novelty, technical quality, potential impact, clarity, and reproducibility (when applicable). Workshop submissions will be handled by EasyChair; <strong>the submission link is as follows</strong>: <a href="https://easychair.org/conferences/?conf=strl2022" target="_blank">https://easychair.org/conferences/?conf=strl2022</a></p> -->

    <p>All questions about submissions should be emailed to mhcd.miua@gmail.com</p>

    

    <h3>Proceedings</h3>

    <p>The accepted papers will appear on the workshop website. We also intend to publish the workshop proceedings with <a target="_blank" href="http://ceur-ws.org/">CEUR-WS.org</a>; this option will be discussed with the authors of accepted papers and is subject to the CEUR-WS.org preconditions. We note that, as STRL 2022 is a workshop, not a conference, submission of the same paper to conferences or journals is acceptable from our standpoint.</p>
    <p><strong>Update</strong>: The back-link to the URL of the workshop proceedings published with CEUR-WS.org is now available at <a target="_blank" href="http://ceur-ws.org/Vol-3190/">http://ceur-ws.org/Vol-3190/</a>.
    <p><a href="#top">Go back to the top</a></p>

<!--     <h2 id="Program">Workshop Program</h2> -->


    
    </ul> 
    <p><a href="#top">Go back to the top</a></p>

    <h2 id="Venue">Venue</h2>
    <p>The workshop will take place on <strong>July 24, 2022</strong> in the room named <strong>Gallerie 11-12</strong> at the Messe Wien Exhibition and Congress Center, in Vienna, Austria.</p>

    <iframe class="directions" src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d10633.76857452723!2d16.407532!3d48.2173602!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x0%3A0x51b94dc6a5158516!2sMesse%20Wien%20Exhibition%20Congress%20Center!5e0!3m2!1sen!2sde!4v1647008253302!5m2!1sen!2sde" width="800" height="600" style="border:0;" allowfullscreen="" loading="lazy"></iframe>
    <p><a href="#top">Go back to the top</a></p>

    <footer>
        &copy; Special Session Organizers
        &nbsp;|&nbsp; Design by <a target="_blank" href="https://github.com/mikepierce">Mike Pierce</a>
        &nbsp;|&nbsp; Sponsored by <a target="_blank" href="https://ijcai-22.org/">IJCAI-ECAI-2022</a> and <a target="_blank" href="http://ceur-ws.org/">CEUR-WS.org</a>
    </footer>

</body>
</html>
